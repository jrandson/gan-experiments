{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.utils.data.DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.pt  training.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls files/MNIST/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a transformation in the dataset images\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "\n",
    "dataset_train = torchvision.datasets.MNIST('files/', train=True, download=True, transform=transform)\n",
    "dataset_test = torchvision.datasets.MNIST('files/', train=False, download=True, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.data.shape)\n",
    "print(dataset_test.data.shape)\n",
    "batch_size_train = 32\n",
    "batch_size_train = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size_train, shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genereator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Genereator, self).__init__()\n",
    "        \n",
    "        output_dense1 = 10 * 10 * 256\n",
    "        self.dense1 = nn.Linear(100, output_dense1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(output_dense1)\n",
    "        \n",
    "        #output = (input - 1)*stride + kernel\n",
    "        #output = (7 - 1)*1 + 5 = 7\n",
    "        self.conv1 = nn.ConvTranspose2d(256,128, kernel_size=(5,5), stride=(1,1), padding=1, bias=False)\n",
    "                     \n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #output = (input - 1)*stride + kernel\n",
    "        #output = (10.75 -5)*2 + 5 = 14\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=(5,5), stride=(1,1), padding=1,bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # output = (input - kernel)*stride - 2*padding + dilat*(kernel-1) + out_padding + 1\n",
    "        # output = (input - 1)*stride + kernel \n",
    "        #output = (16.5-5)*2 + 5 = 28\n",
    "        self.conv3 = nn.ConvTranspose2d(64,1, kernel_size=(4,4), stride=(2,2), padding=1, bias=False)        \n",
    "        self.batch_norm4 = nn.BatchNorm2d(1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "            \n",
    "        x = self.dense1(x)\n",
    "        x = F.leaky_relu(self.batch_norm1(x))\n",
    "        \n",
    "        x = x.reshape((-1, 256, 10,10))       \n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.batch_norm2(x)) \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.batch_norm3(x))   \n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(self.batch_norm4(x))  \n",
    "        x = torch.squeeze(x,1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y):\n",
    "        super(Discriminator, self).__init__()        \n",
    "        \n",
    "        #out_dim = (input_dim - kernel_size)/stride + 1 = (28 - 3)/2 + 1 = ~= 14\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3,3), stride=(2,2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        #out_put_dim = (14 - 3)/2 + 1 ~= 7\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.input_dim = 128 * 6 * 6\n",
    "        self.dense = nn.Linear(self.input_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.unsqueeze(x,1)\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.bn1(x))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.bn2(x))\n",
    "        \n",
    "        x = x.reshape(-1, self.input_dim)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/randson/.local/lib/python3.6/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "gen_model = Genereator()\n",
    "noise = torch.randn([32,100])\n",
    "gen_image = gen_model(noise).data.numpy()\n",
    "print(gen_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(gen_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f58b19fa9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAZ1ElEQVR4nO2deXiV1bXG38UQZFKZgswKpVCqgBoQCk5QGQsUWkEsgqUVi9Aqk0X6WLFqq3KdQZQKRS+KCggiRYRLoQ6AEiiCCCJQpghEQCBomff9I8c+uZr9bpqEc/Lc/f6eJ09Ozi/rnM2XLL6Ts769ljnnIIT4/0+JVC9ACJEclOxCRIKSXYhIULILEQlKdiEioVQyn6x8+fKuUqVKXv/ll1+G4r3uX//6F40955xz+OIClCrlP1ShdZcpU4b6kydPUn/69GnqWUXFzGgs+3kAwNGjR6kPrb1kyZJe99VXX9HY9PR06rOzs6kvW7as1506dYrGsp83EP6ZV65cmfrDhw97XYUKFWjswYMH6bqOHTuW7w+9UMluZp0APAGgJIDnnHMPsu+vVKkShg4d6vUffPABfb6WLVt63dq1a2ls48aNqS9Rgr/IqVKlite9//77NLZ+/frU79u3j/rjx48X2JcuXZrG9uzZk/pPPvmE+gMHDlB/3nnned2aNWto7G233Ub9k08+SX3Tpk297siRIzQ29J9gZmYm9b1796Z+8eLFXteqVSsaO2/ePK9buHCh1xX4ZbyZlQQwAUBnAE0A9DWzJgV9PCHE2aUwf7O3BLDZObfVOXccwMsAehTNsoQQRU1hkr0WgJ15vt6VuO//YGaDzCzTzDJDf+cIIc4eZ/3deOfcJOdchnMug73BJoQ4uxQm2bMA1Mnzde3EfUKIYkhhkn0lgIZmdpGZpQG4AcDcolmWEKKoscLsejOzLgAeR27pbYpz7gH2/dWqVXOs1FOzZk36fKxUEypP1a5dm/rQcdi7d6/X/eAHP6Cxn332GfVt27alfty4cdQ3aNDA69577z0a+9JLL1E/cOBA6u+//37qR48e7XVdu3alsatWraL+6aefpv7uu+/2uvbt29NY9vMGwtcfhMqxDz30kNc9+CCtYKNz585eN27cOOzYsaPo6+zOufkA5hfmMYQQyUGXywoRCUp2ISJByS5EJCjZhYgEJbsQkaBkFyISClVn/0+pW7euGzlypNe/8847NP6WW24pcGy9evWonzFjBvVXX3211z377LM0ltWaAWDlypXU9+3bl/qnnnrK60LXFyxfvpz65557jvqpU6dSv379eq+rU6eO1wF8PzoQPm6jRo3yuo0bN9LYCy64gHq2RRUAOnXqRP0rr7zidf369aOxK1as8LqZM2ciOzs73zq7zuxCRIKSXYhIULILEQlKdiEiQckuRCQo2YWIhKSW3qpVq+Z69erl9aFyB2uh+53vfIfGbtq0ifrdu3dT36xZM6+75ppraOwvf/lL6llJEQh3cJ07199GIFS+6tixI/Vvvvkm9T/96U+pZ+WxTz/9lMbWqFGD+qpVq1K/fft2r6tYsSKNDbUmP//886nfsWMH9YMHD/a6BQsW0NiMjAyvmzBhArKyslR6EyJmlOxCRIKSXYhIULILEQlKdiEiQckuRCQo2YWIhKSObC5VqhSqVavm9WzrHsCnemZl8fkULVq0oP7dd9+lvly5cl43fvx4Gjtz5kzq77rrLuqHDBlCPbsGgI1MBoA5c+ZQP2jQIOpDbbLZFlk20RcAmjThc0JDI59Zy+XQ1t0xY8ZQ/8QTT1D/+9//nvolS5YU+LmnTJnidSdOnPA6ndmFiAQluxCRoGQXIhKU7EJEgpJdiEhQsgsRCUp2ISIhqXX2kydPIjs72+urVKlC45955hmv6969O41lzwsAL7/8coGfu0OHDjR29erV1M+fzwfhXnfdddRnZmZ6XZ8+fWjskSNHqA/trR4+fDj1jRo18roLL7yQxtavX5961o45FN+8eXMaa5bvlvB/w/bKA8CyZcuoZ/0Vfv7zn9PYLl26eF2JEv7zd6GS3cy2AcgBcArASeecf1e9ECKlFMWZ/Vrn3L4ieBwhxFlEf7MLEQmFTXYHYKGZrTKzfC+iNrNBZpZpZplHjx4t5NMJIQpKYV/Gt3XOZZlZOoBFZrbROfd23m9wzk0CMAnIbThZyOcTQhSQQp3ZnXNZic/ZAGYDaFkUixJCFD0FTnYzK29mFb++DaADgI+KamFCiKKlMC/jqwOYnahHlgLwknOOFmXT0tJQt25drw+N0b3zzju97sEHH6SxoT3nEydOpL5x48Ze98knn9BYthceANq0aUN9qO76/vvve12rVq1obKiO/vHHH1N/8803U/+jH/3I60K16tCoa3Z9AQD06NHD6x5++GEa+8UXX1DfsGFD6n/4wx9Sn5OT43V33HEHjZ08ebLXHT9+3OsKnOzOua0A/F0ThBDFCpXehIgEJbsQkaBkFyISlOxCRIKSXYhISOoW1+PHj2Pnzp1eHxp9PG7cOK9jWymBcMtjtm0Q4OOku3XrRmO7du1KfWj8LxvJDABs7PaGDRtobOgS5tDo4n79+lH/hz/8wetuuukmGhtqLR4a2bxw4UKvC5XGbrjhBupnzZpVKN+uXTuve/XVV2ksG2VdunRpr9OZXYhIULILEQlKdiEiQckuRCQo2YWIBCW7EJGgZBciEpJaZ09PT6djl0MjeC+++GKvu+WWW2hsqJ4cGqvM6qIjRoygsWykMhBuc71mzRrqq1ev7nWhmm2o3nzVVVdRf/jwYeo7duzodezaBYCPXAaAwYMHUz9s2DCvmz59Oo09dOgQ9Xv27KE+1Nr83nvv9bq//OUvNJaNF09LS/M6ndmFiAQluxCRoGQXIhKU7EJEgpJdiEhQsgsRCUp2ISIhqXX27OxsTJgwwetZu2aA1xeHDh1KY9PT06nftWsX9aVK+Q/VqVOnaOy6deuoD/27QzXdDz74wOtC+7LXrl1L/aOPPkp9gwYNqGfXTpx77rmFeu5Qq+m//e1vXte2bVsaG2pTHWr/Hbpu47777vO6UHvuXr16ed3Jkye9Tmd2ISJByS5EJCjZhYgEJbsQkaBkFyISlOxCRIKSXYhISGqdvWTJkrRH+r59+2j8lVde6XWhscm1atWiPlTTHTNmjNcNHDiQxj7wwAPUh/acX3/99dSfPn3a67KysmhsqPd6qA9AqE7fu3dvrzt48CCNZdcPAMCWLVuoZ9dlhH4mw4cPp37z5s3Uh64/WLZsmdexXvsAsHr1aup9BM/sZjbFzLLN7KM891U2s0Vm9mnic6UCPbsQImmcycv4qQA6feO+0QAWO+caAlic+FoIUYwJJrtz7m0AB75xdw8AzyduPw/gx0W8LiFEEVPQN+iqO+d2J27vAeBtgmZmg8ws08wyQ3PDhBBnj0K/G+9ypwp6Jws65yY55zKccxlly5Yt7NMJIQpIQZN9r5nVAIDEZ94eVQiRcgqa7HMBDEjcHgDg9aJZjhDibGFstjcAmNl0ANcAqApgL4B7AMwB8CqAugC2A+jtnPvmm3jfonLlyq5Dhw5ef91119F4Nts91L/8iiuuoH7evHnUszr8nDlzaGzovYratWtTH9rvzmrZoZn3W7dupT7U2z20tvXr13tduXLlCvXYbI4AwPekh3oMsGsXACAnJ4f6Sy65hPrPP//c60qWLEljWX+DpUuX4uDBg5afC15U45zr61HtQ7FCiOKDLpcVIhKU7EJEgpJdiEhQsgsRCUp2ISIhqVtcK1SogNatW3t9xYoVaXxGRobXsS2DAHDppZdSP3LkSOpZi94333yTxnbr1o36P/3pT9T/5je/ob5ly5Zed+GFF9LYAQMGUB/aThkqj7HW4TNmzKCx999/P/WhbaQ/+clPvK5ECX6ee+mll6gvU6YM9azdM8CP+9ixY2nskiVLvE4jm4UQSnYhYkHJLkQkKNmFiAQluxCRoGQXIhKU7EJEQlLr7EeOHKHtfVkdHeAjeMeNG0djWStoINxSmW1JDNWib7zxRupD/+7QaOOaNWt6XajVc6htcahlMmvvDfB20LfffjuNPXCA75oOxXfp0sXrJk+eTGOfeeYZ6mfPnk19aMx2//79vW7atGk09sSJE1537Ngxr9OZXYhIULILEQlKdiEiQckuRCQo2YWIBCW7EJGgZBciEpK+n/2qq67y+g8//JDGsz3pbN80AHz55ZfUDx48mHo2Vjm0D5+NqQaAF198kfrQOGm2nz2075rVbIFwq+nQfvnq1b2TwYJ7yu+77z7q2XUXAB8JPXToUBq7YMEC6jdt2kT90qVLqa9QoYLX9evXj8YuX77c61atWuV1OrMLEQlKdiEiQckuRCQo2YWIBCW7EJGgZBciEpTsQkRCUuvszjm63/bQoUM0vnnz5l43depUGnvvvfdSP2vWLOrZ3ul27drR2Keeeor6yy67jPrx48dTz64hYCOTQ7EAMH36dOoff/xx6lu1auV1Tz/9NI2dOHEi9aHRxsOGDfO6UE/6rKws6tPT06lv354POX777be9bvTo0TSW9RA4deqU1wXP7GY2xcyyzeyjPPeNNbMsM1uT+PB3CRBCFAvO5GX8VACd8rn/Medc88TH/KJdlhCiqAkmu3PubQC8P5AQothTmDfohprZ2sTL/Eq+bzKzQWaWaWaZR44cKcTTCSEKQ0GTfSKABgCaA9gN4BHfNzrnJjnnMpxzGezifyHE2aVAye6c2+ucO+WcOw3gzwD8266EEMWCAiW7mdXI82VPAB/5vlcIUTwI1tnNbDqAawBUNbNdAO4BcI2ZNQfgAGwDcOuZPFmJEiVQvnx5r2/SpAmN37Vrl9eFapMNGzakPlTrnjJlitf97Gc/o7FstjsQXhurnQLA1Vdf7XW/+93vaGyohh/qr/7VV19R36NHD6/buXMnjQ31KFi8eDH1H33kPwfdeiv/lZ0/nxeYypUrR31on//cuXO9jvXaB4Bf/epXXnf69GmvCya7c65vPnfz3wAhRLFDl8sKEQlKdiEiQckuRCQo2YWIBCW7EJFgzrmkPVl6errr06eP14e2W7LLbUPbIe+++27qW7duTX3p0qW9btSoUTQ2tMU1VN4KtYNOS0vzulAb6ttuu436Cy64gPratWtTv3HjRq/74osvaGyzZs2o37dvH/XVqlXzulAr6NAW11q1alGfnZ1NfaNGjbwuVGplv4szZ85Edna25ed0ZhciEpTsQkSCkl2ISFCyCxEJSnYhIkHJLkQkKNmFiISktpJOS0uj9cnt27fT+P79+3tdqKVxr169qN+zZw/1Xbt29bpQjb9BgwbUh+qqI0aMoP6NN97wur///e809qabbqI+tPbQFtfu3bt7HduaC4THKn/3u9+lno1sDm1RrVevHvX33HMP9aGxy2xMN2tbDgDPPvus17EtrjqzCxEJSnYhIkHJLkQkKNmFiAQluxCRoGQXIhKU7EJEQlL3s1epUsV17NjR60OtpFnNuE2bNjQ2VJNlbaoBYMuWLV537rnn0tj9+/dTX7VqVeqbNm1K/YoVK7wuNE562bJl1J9//vnUh/Z1s3p03bp1aezatWupHzt2LPWVKnmnkuGdd96hsaF/dyj+zjvvpH7btm1eF5qcxJ77rbfewv79+7WfXYiYUbILEQlKdiEiQckuRCQo2YWIBCW7EJGgZBciEpK6n71s2bK49NJLvf69996j8YMGDfK6devW0diSJUtS3759e+pZLX3evHk0lu3DB8L7+Lt160Y92w+/ZMkSGjtkyBDqH3nkEeorVqxIfc+ePb3ugQceoLGh6xNCfQQyMzO9js0gOJPHnjRpEvWsjg7wn8vFF19MYy+//HKvYzX44JndzOqY2RIz+9jM1pvZ7Yn7K5vZIjP7NPHZfwWDECLlnMnL+JMARjjnmgBoBWCImTUBMBrAYudcQwCLE18LIYopwWR3zu12zq1O3M4BsAFALQA9ADyf+LbnAfz4bC1SCFF4/qM36MzsQgCXAngfQHXn3O6E2gOguidmkJllmllmaJabEOLsccbJbmYVAMwCcIdz7nBe53J30+S7o8Y5N8k5l+GcyyhfvnyhFiuEKDhnlOxmVhq5if6ic+61xN17zaxGwtcAwMdWCiFSSrD0ZmYGYDKADc65vPN/5wIYAODBxOfXQ4+Vk5NDSw6htsYTJkzwul//+tc0tlQp/k8dM2YM9aw0d+jQIRobGv+7YcMG6ocNG0b99ddf73XnnHMOjb3yyiupDx3XmjVrUr93716ve+yxx2hsqDzGSlAA8Nlnn3ld586daWxou3WLFi2oHzx4MPVs+26oFMt+l0+ePOmPo4+aSxsANwFYZ2ZrEveNQW6Sv2pmvwCwHUDvM3gsIUSKCCa7c+5dAPluhgfAr0QRQhQbdLmsEJGgZBciEpTsQkSCkl2ISFCyCxEJSd3iWq5cOTRv3tzrQ9tQ//jHP3rdqFGjaOyUKVOo79ChA/WVK1f2uu9973s0tnbt2tSvXr2a+lAt+6233vK6AQMG0NhQG+vvf//71K9Zs4b6u+66y+tC46RLlODnotCYbfYzTUtLo7FdunShvmHDhtTv3LmT+vr163vdiRMnaOzRo0e9TiObhRBKdiFiQckuRCQo2YWIBCW7EJGgZBciEpTsQkRCUuvsJ06coHuMGzduTOMHDhzodaH9w3PnzqX+n//8J/WbN2/2uoceeojGhloDT506lfqNGzdS37ZtW68rXbo0jc3JyaF+/Pjx1LORzABw3nnned3IkSNp7Pz586kPtcF+8sknve6SSy6hseyaDgCYNm0a9SHYcQ/9zFidnY1g15ldiEhQsgsRCUp2ISJByS5EJCjZhYgEJbsQkaBkFyISklpnr1ixIu2/Huqf3q9fP68L9dpm+9EB4B//+Af11157rdf99a9/pbG33nor9dWqVaOe9V4HgIMHD3rdjTfeSGNfeOEF6jdt2kT9K6+8Qj3rmR/qGz9jxgzqQyO+We/3FStW0NjQ9QcLFiygvnv37tQfP37c69q1a0dj58yZ43WqswshlOxCxIKSXYhIULILEQlKdiEiQckuRCQo2YWIhDOZz14HwAsAqgNwACY5554ws7EAbgHweeJbxzjn6AbkgwcPYvbs2V6fnp5O17JlyxavC812nzRpEvWh+OXLl3tdZmYmjQ31Xg/ttb/ooouo37dvn9e1bt2axu7YsYP6UO/2Hj16UP/oo4963fDhw2lsqOd9p06dqGe92UP9C7Zu3Up9qPfC4cOHqa9Tp47XsX34AFCjRg2vY3X2M7mo5iSAEc651WZWEcAqM1uUcI855/7rDB5DCJFizmQ++24AuxO3c8xsA4BaZ3thQoii5T/6m93MLgRwKYD3E3cNNbO1ZjbFzCp5YgaZWaaZZR47dqxQixVCFJwzTnYzqwBgFoA7nHOHAUwE0ABAc+Se+R/JL845N8k5l+GcyyhTpkwRLFkIURDOKNnNrDRyE/1F59xrAOCc2+ucO+WcOw3gzwBanr1lCiEKSzDZzcwATAawwTn3aJ77874l2BPAR0W/PCFEUWHsrXoAMLO2AN4BsA7A1/NgxwDoi9yX8A7ANgC3Jt7M81KvXj3329/+1uu3bdtG11K9enWvY2U5IFzmWbRoEfWs9fDSpUtp7M0330x9qOz32muvUf/66697Xajsx0qKAFCvXj3q3333XeorVKjgdaGtvaGtwZ07d6a+ZUv/i826devSWNaeGwi3D2/WrBn106dP9zpWngaAxx9/3OumTZuGPXv2WH7uTN6NfxdAfsG8qbcQolihK+iEiAQluxCRoGQXIhKU7EJEgpJdiEhQsgsRCcE6e1FSpUoV17FjR6/v378/jWctm/v27UtjQ+N/GzVqRD2rR/fp04fGvvHGG9Rffvnl1K9bt476smXLel3oEuWmTZtSz9oWA0CLFi2oX7lypde1adOGxi5btoz60NrZePArrriCxoa2LYdak58+fbrAPrSHZP/+/V7H6uw6swsRCUp2ISJByS5EJCjZhYgEJbsQkaBkFyISlOxCREJS6+xm9jmAvLOVqwLw90FOLcV1bcV1XYDWVlCKcm31nHP5NgpIarJ/68nNMp1zGSlbAKG4rq24rgvQ2gpKstaml/FCRIKSXYhISHWy85lMqaW4rq24rgvQ2gpKUtaW0r/ZhRDJI9VndiFEklCyCxEJKUl2M+tkZp+Y2WYzG52KNfgws21mts7M1pgZ39R89tcyxcyyzeyjPPdVNrNFZvZp4nO+M/ZStLaxZpaVOHZrzKxLitZWx8yWmNnHZrbezG5P3J/SY0fWlZTjlvS/2c2sJIBNAK4DsAvASgB9nXMfJ3UhHsxsG4AM51zKL8Aws6sAHAHwgnPu4sR9DwM44Jx7MPEfZSXnnH/yRnLXNhbAkVSP8U5MK6qRd8w4gB8DuBkpPHZkXb2RhOOWijN7SwCbnXNbnXPHAbwMoEcK1lHscc69DeDAN+7uAeD5xO3nkfvLknQ8aysWOOd2O+dWJ27nAPh6zHhKjx1ZV1JIRbLXArAzz9e7ULzmvTsAC81slZkNSvVi8qF6njFbewD4Z2KlhuAY72TyjTHjxebYFWT8eWHRG3Tfpq1z7jIAnQEMSbxcLZa43L/BilPt9IzGeCeLfMaM/5tUHruCjj8vLKlI9iwAdfJ8XTtxX7HAOZeV+JwNYDaK3yjqvV9P0E18zk7xev5NcRrjnd+YcRSDY5fK8eepSPaVABqa2UVmlgbgBgBzU7COb2Fm5RNvnMDMygPogOI3inougAGJ2wMA+Ee4JpniMsbbN2YcKT52KR9/7pxL+geALsh9R34LgN+lYg2eddUH8GHiY32q1wZgOnJf1p1A7nsbvwBQBcBiAJ8C+B8AlYvR2v4buaO91yI3sWqkaG1tkfsSfS2ANYmPLqk+dmRdSTluulxWiEjQG3RCRIKSXYhIULILEQlKdiEiQckuRCQo2YWIBCW7EJHwv8DVnoaJTH+HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dense): Linear(in_features=4608, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "discr_model = Discriminator(28,28)\n",
    "print(discr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = F.mse_loss(torch.ones_like(real_output), real_output)\n",
    "    fake_loss = F.mse_loss(torch.ones_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss    \n",
    "    return total_loss\n",
    "    \n",
    "def generator_loss(fake_output):\n",
    "    loss = F.mse_loss(torch.ones_like(fake_output), fake_output)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn([32,100])\n",
    "gen_image = gen_model(noise)\n",
    "pred = discr_model(gen_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand(num_examples_to_generate, noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = dataset_train.data, dataset_train.targets\n",
    "X_test, y_test = dataset_test.data, dataset_test.targets\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6d075ea06a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mreal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57564c883664>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n"
     ]
    }
   ],
   "source": [
    "gen_opt = optim.Adam(gen_model.parameters(), lr=1e-3)\n",
    "discr_opt = optim.Adam(discr_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    generated_images = gen_model(noise)\n",
    "    \n",
    "    real_output = discr_model(X_train.type(torch.float32))\n",
    "    fake_output = discr_model(generated_images)\n",
    "    \n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    discr_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gen_opt.zero_grad()\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    \n",
    "    discr_opt.zero_grad()\n",
    "    discr_loss.backward()\n",
    "    discr_opt.step() \n",
    "    \n",
    "    print(\"{} from {}\\tloss gen: {.:4f}\\tloss disc: {.:4f}\".format(epoch, EPOCHS), end=\"\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd-env",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
